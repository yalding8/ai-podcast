#!/usr/bin/env python3
"""
æ’­å®¢æ–°é—»é‡‡é›†ç³»ç»Ÿ - é›†æˆæµ‹è¯•è„šæœ¬
æ¼”ç¤ºä»é‡‡é›†åˆ°å¤„ç†çš„å®Œæ•´æµç¨‹
"""

import json
import os
from datetime import datetime
from typing import List, Dict

class NewsAggregator:
    """æ–°é—»èšåˆå™¨ - æ ¸å¿ƒå¼•æ“"""
    
    def __init__(self):
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œè‡ªåŠ¨é€‚é…ä»»ä½•æ“ä½œç³»ç»Ÿ
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        self.data_dir = os.path.join(project_root, "data")
        self.sources = self.load_source_config()
        os.makedirs(self.data_dir, exist_ok=True)
    
    def load_source_config(self) -> Dict:
        """åŠ è½½ä¿¡æ¯æºé…ç½®"""
        return {
            "tier1": [
                {"name": "ICEF Monitor", "url": "https://monitor.icef.com/feed/", "priority": 95},
                {"name": "The PIE News", "url": "https://thepienews.com/feed/", "priority": 95},
                {"name": "Inside Higher Ed", "url": "https://www.insidehighered.com/rss/all", "priority": 90},
            ],
            "tier2": {
                "newscatcher": {
                    "enabled": False,
                    "queries": ["international education", "student visa"],
                    "countries": ["US", "GB", "CA", "AU"]
                },
                "gdelt": {
                    "enabled": True,
                    "queries": [
                        "international student OR study abroad",
                        "university admission OR college admission",
                        "student visa policy"
                    ],
                    "timespan": "3d"
                }
            },
            "tier3": {
                "rsshub": {
                    "enabled": True,
                    "routes": [
                        "https://www.ielts.org/news-and-insights",
                        "ets/news",
                        "gov/uk/visas-immigration"
                    ]
                }
            }
        }
    
    def collect_demo_data(self) -> List[Dict]:
        """ç”Ÿæˆæ¼”ç¤ºæ•°æ®ï¼ˆæ¨¡æ‹ŸçœŸå®é‡‡é›†ç»“æœï¼‰"""
        print("=" * 70)
        print("ğŸ” æ–°é—»é‡‡é›†ç³»ç»Ÿ - æ¼”ç¤ºæ¨¡å¼")
        print("=" * 70)
        print("\næ­£åœ¨æ¨¡æ‹Ÿä»å¤šä¸ªæ¥æºé‡‡é›†æ–°é—»...\n")
        
        demo_articles = [
            {
                "id": "demo_001",
                "source": "ICEF Monitor",
                "source_tier": 1,
                "title": "UK Government Announces New Graduate Visa Route Changes",
                "url": "https://monitor.icef.com/2025/01/uk-graduate-visa-changes/",
                "published_date": "2025-01-28T09:00:00Z",
                "language": "en",
                "country": "GB",
                "category": "policy",
                "tags": ["visa", "UK", "graduate", "policy_change"],
                "priority_score": 95,
                "summary": "è‹±å›½æ”¿åºœå®£å¸ƒå¯¹æ¯•ä¸šç”Ÿç­¾è¯è·¯å¾„è¿›è¡Œé‡å¤§è°ƒæ•´ï¼Œå½±å“2025å¹´åçš„å›½é™…å­¦ç”Ÿã€‚æ–°æ”¿ç­–è¦æ±‚æ›´é«˜çš„è–ªèµ„é—¨æ§›å’Œæ›´ä¸¥æ ¼çš„æ‹…ä¿è¦æ±‚ã€‚",
                "key_points": [
                    "æ–°çš„è–ªèµ„é—¨æ§›æé«˜è‡³Â£28,000",
                    "æ‹…ä¿è¦æ±‚æ›´ä¸¥æ ¼",
                    "2025å¹´4æœˆç”Ÿæ•ˆ"
                ],
                "entities": {
                    "organizations": ["UK Home Office", "UKVI"],
                    "locations": ["United Kingdom"]
                }
            },
            {
                "id": "demo_002",
                "source": "The PIE News",
                "source_tier": 1,
                "title": "US Universities Report 12% Increase in International Applications",
                "url": "https://thepienews.com/2025/01/us-intl-applications-surge/",
                "published_date": "2025-01-27T14:30:00Z",
                "language": "en",
                "country": "US",
                "category": "admission",
                "tags": ["USA", "applications", "statistics"],
                "priority_score": 90,
                "summary": "ç¾å›½å¤§å­¦å›½é™…å­¦ç”Ÿç”³è¯·é‡åŒæ¯”å¢é•¿12%ï¼Œå…¶ä¸­æ¥è‡ªä¸­å›½å’Œå°åº¦çš„ç”³è¯·å¢é•¿æœ€ä¸ºæ˜¾è‘—ã€‚å·¥ç¨‹å’Œè®¡ç®—æœºç§‘å­¦ä¸“ä¸šæœ€å—æ¬¢è¿ã€‚",
                "key_points": [
                    "å›½é™…ç”³è¯·æ€»é‡å¢é•¿12%",
                    "ä¸­å›½ã€å°åº¦å­¦ç”Ÿç”³è¯·å¢é•¿æœ€å¿«",
                    "STEMä¸“ä¸šæŒç»­çƒ­é—¨"
                ],
                "entities": {
                    "organizations": ["Common App", "NAFSA"],
                    "locations": ["United States", "China", "India"]
                }
            },
            {
                "id": "demo_003",
                "source": "GDELT",
                "source_tier": 2,
                "title": "Australia Extends Post-Study Work Rights for Master's Graduates",
                "url": "https://www.homeaffairs.gov.au/news/post-study-work-extension",
                "published_date": "2025-01-26T08:15:00Z",
                "language": "en",
                "country": "AU",
                "category": "policy",
                "tags": ["Australia", "PSW", "visa", "masters"],
                "priority_score": 88,
                "summary": "æ¾³å¤§åˆ©äºšæ”¿åºœå®£å¸ƒå»¶é•¿ç¡•å£«æ¯•ä¸šç”Ÿçš„æ¯•ä¸šåå·¥ä½œæƒåˆ©è‡³3å¹´ï¼Œä»¥å¸å¼•æ›´å¤šé«˜æŠ€èƒ½å›½é™…å­¦ç”Ÿã€‚æ­¤ä¸¾è¢«è§†ä¸ºä¸åŠ æ‹¿å¤§å’Œè‹±å›½ç«äº‰äººæ‰çš„é‡è¦ä¸¾æªã€‚",
                "key_points": [
                    "ç¡•å£«æ¯•ä¸šç”ŸPSWå»¶é•¿è‡³3å¹´",
                    "åšå£«ç”Ÿå»¶é•¿è‡³4å¹´",
                    "ç«‹å³ç”Ÿæ•ˆ"
                ],
                "entities": {
                    "organizations": ["Dept of Home Affairs"],
                    "locations": ["Australia"]
                }
            },
            {
                "id": "demo_004",
                "source": "Times Higher Education",
                "source_tier": 1,
                "title": "QS World University Rankings 2026: Major Shifts Expected",
                "url": "https://www.timeshighereducation.com/qs-2026-preview",
                "published_date": "2025-01-25T11:00:00Z",
                "language": "en",
                "country": "GB",
                "category": "rankings",
                "tags": ["rankings", "QS", "universities"],
                "priority_score": 85,
                "summary": "QSå°†äº6æœˆå‘å¸ƒ2026å¹´ä¸–ç•Œå¤§å­¦æ’åï¼Œé¢„è®¡è¯„ä¼°æ–¹æ³•å°†æœ‰é‡å¤§è°ƒæ•´ï¼Œæ›´åŠ é‡è§†å°±ä¸šèƒ½åŠ›å’Œå¯æŒç»­å‘å±•æŒ‡æ ‡ã€‚",
                "key_points": [
                    "æ–°å¢å°±ä¸šèƒ½åŠ›æƒé‡",
                    "å¯æŒç»­å‘å±•æˆä¸ºæ–°æŒ‡æ ‡",
                    "6æœˆ6æ—¥æ­£å¼å‘å¸ƒ"
                ],
                "entities": {
                    "organizations": ["QS", "THE"],
                    "locations": []
                }
            },
            {
                "id": "demo_005",
                "source": "IELTSå®˜ç½‘",
                "source_tier": 3,
                "title": "IELTS Launches New Computer-Delivered Test Format in 50 Cities",
                "url": "https://www.ielts.org/news/computer-delivered-expansion",
                "published_date": "2025-01-24T10:00:00Z",
                "language": "en",
                "country": "Global",
                "category": "exam",
                "tags": ["IELTS", "exam", "computer-based"],
                "priority_score": 82,
                "summary": "é›…æ€å®£å¸ƒåœ¨å…¨çƒ50ä¸ªåŸå¸‚æ¨å‡ºæ–°çš„æœºè€ƒæ ¼å¼ï¼Œæä¾›æ›´çµæ´»çš„è€ƒè¯•æ—¥æœŸå’Œæ›´å¿«çš„æˆç»©å‘å¸ƒï¼ˆ3å¤©å†…ï¼‰ã€‚æ–°æ ¼å¼åŒ…æ‹¬æ”¹è¿›çš„ç”¨æˆ·ç•Œé¢å’Œè¾…åŠ©åŠŸèƒ½ã€‚",
                "key_points": [
                    "50ä¸ªæ–°åŸå¸‚æ¨å‡ºæœºè€ƒ",
                    "3å¤©å†…å‡ºæˆç»©",
                    "æ”¹è¿›çš„ç”¨æˆ·ç•Œé¢"
                ],
                "entities": {
                    "organizations": ["IELTS", "British Council"],
                    "locations": []
                }
            }
        ]
        
        print(f"âœ… æˆåŠŸæ¨¡æ‹Ÿé‡‡é›† {len(demo_articles)} æ¡æ–°é—»\n")
        
        # æ˜¾ç¤ºé‡‡é›†ç»“æœ
        for article in demo_articles:
            print(f"ğŸ“° [{article['source']}] {article['title']}")
            print(f"   ğŸ·ï¸  {' | '.join(article['tags'])}")
            print(f"   â­ ä¼˜å…ˆçº§: {article['priority_score']}")
            print()
        
        return demo_articles
    
    def deduplicate(self, articles: List[Dict]) -> List[Dict]:
        """å»é‡å¤„ç†"""
        print("\n" + "=" * 70)
        print("ğŸ”„ å»é‡ä¸èšç±»...")
        print("=" * 70)
        
        # ç®€åŒ–æ¼”ç¤ºï¼šåŸºäºæ ‡é¢˜ç›¸ä¼¼åº¦
        seen_titles = set()
        unique_articles = []
        duplicates = 0
        
        for article in articles:
            title_lower = article['title'].lower()
            # ç®€å•çš„é‡å¤æ£€æµ‹ï¼ˆå®é™…åº”ç”¨ä¸­ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦ï¼‰
            is_duplicate = any(
                self._similarity(title_lower, seen.lower()) > 0.8 
                for seen in seen_titles
            )
            
            if not is_duplicate:
                unique_articles.append(article)
                seen_titles.add(article['title'])
            else:
                duplicates += 1
        
        print(f"ğŸ“Š åŸå§‹æ–°é—»: {len(articles)} æ¡")
        print(f"ğŸ—‘ï¸  å»é™¤é‡å¤: {duplicates} æ¡")
        print(f"âœ… ä¿ç•™å”¯ä¸€: {len(unique_articles)} æ¡\n")
        
        return unique_articles
    
    def _similarity(self, s1: str, s2: str) -> float:
        """ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦è®¡ç®—"""
        words1 = set(s1.split())
        words2 = set(s2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union)
    
    def categorize_and_score(self, articles: List[Dict]) -> List[Dict]:
        """åˆ†ç±»å’Œæ‰“åˆ†"""
        print("=" * 70)
        print("ğŸ“Š åˆ†ç±»ä¸ä¼˜å…ˆçº§è¯„åˆ†...")
        print("=" * 70)
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        categories = {}
        for article in articles:
            cat = article.get('category', 'other')
            categories[cat] = categories.get(cat, 0) + 1
        
        print("\nç±»åˆ«åˆ†å¸ƒ:")
        for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            print(f"   {cat:15s}: {count} æ¡")
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        articles.sort(key=lambda x: x.get('priority_score', 0), reverse=True)
        
        print("\nä¼˜å…ˆçº§æ’åºï¼ˆTop 3ï¼‰:")
        for i, article in enumerate(articles[:3], 1):
            print(f"   {i}. [{article['priority_score']}åˆ†] {article['title']}")
        
        print()
        return articles
    
    def generate_summary(self, articles: List[Dict]) -> Dict:
        """ç”Ÿæˆæ’­å®¢å†…å®¹æ‘˜è¦"""
        print("=" * 70)
        print("ğŸ“ ç”Ÿæˆæ’­å®¢è„šæœ¬æ‘˜è¦...")
        print("=" * 70)
        
        # æŒ‰ç±»åˆ«ç»„ç»‡
        categorized = {}
        for article in articles:
            cat = article.get('category', 'other')
            if cat not in categorized:
                categorized[cat] = []
            categorized[cat].append(article)
        
        # ç”Ÿæˆè„šæœ¬ç»“æ„
        script = {
            "episode_number": 1,
            "date": datetime.now().strftime("%Y-%m-%d"),
            "title": f"å›½é™…æ•™è‚²èµ„è®¯ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}",
            "sections": []
        }
        
        # é‡è¦æ”¿ç­–å˜åŒ–
        if 'policy' in categorized:
            script['sections'].append({
                "title": "æœ¬å‘¨é‡è¦æ”¿ç­–",
                "articles": categorized['policy'][:2]
            })
        
        # é™¢æ ¡åŠ¨æ€
        if 'admission' in categorized or 'rankings' in categorized:
            admission_articles = categorized.get('admission', [])
            ranking_articles = categorized.get('rankings', [])
            script['sections'].append({
                "title": "é™¢æ ¡ä¸æ’ååŠ¨æ€",
                "articles": (admission_articles + ranking_articles)[:2]
            })
        
        # è€ƒè¯•æ›´æ–°
        if 'exam' in categorized:
            script['sections'].append({
                "title": "è€ƒè¯•æœºæ„æ›´æ–°",
                "articles": categorized['exam'][:2]
            })
        
        # æ˜¾ç¤ºè„šæœ¬ç»“æ„
        print(f"\nèŠ‚ç›®æ ‡é¢˜: {script['title']}")
        print(f"èŠ‚ç›®æ—¥æœŸ: {script['date']}")
        print(f"\nå†…å®¹ç»“æ„:")
        
        for i, section in enumerate(script['sections'], 1):
            print(f"\n{i}. {section['title']}")
            for j, article in enumerate(section['articles'], 1):
                print(f"   {i}.{j} {article['title']}")
                print(f"       {article['summary'][:100]}...")
        
        return script
    
    def save_results(self, articles: List[Dict], script: Dict):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        print("\n" + "=" * 70)
        print("ğŸ’¾ ä¿å­˜ç»“æœ...")
        print("=" * 70)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
        
        # ä¿å­˜åŸå§‹æ•°æ®
        articles_file = os.path.join(self.data_dir, f"articles_{timestamp}.json")
        with open(articles_file, 'w', encoding='utf-8') as f:
            json.dump(articles, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ–°é—»æ•°æ®: {articles_file}")
        
        # ä¿å­˜è„šæœ¬
        script_file = os.path.join(self.data_dir, f"script_{timestamp}.json")
        with open(script_file, 'w', encoding='utf-8') as f:
            json.dump(script, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ’­å®¢è„šæœ¬: {script_file}")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_file = os.path.join(self.data_dir, f"report_{timestamp}.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# {script['title']}\n\n")
            f.write(f"**æ—¥æœŸ**: {script['date']}\n\n")
            f.write(f"**é‡‡é›†æ–°é—»æ•°**: {len(articles)}\n\n")
            f.write("---\n\n")
            
            for section in script['sections']:
                f.write(f"## {section['title']}\n\n")
                for article in section['articles']:
                    f.write(f"### {article['title']}\n\n")
                    f.write(f"**æ¥æº**: {article['source']} | **å›½å®¶**: {article['country']}\n\n")
                    f.write(f"{article['summary']}\n\n")
                    f.write(f"**å…³é”®è¦ç‚¹**:\n")
                    for point in article['key_points']:
                        f.write(f"- {point}\n")
                    f.write(f"\n[é˜…è¯»åŸæ–‡]({article['url']})\n\n")
                    f.write("---\n\n")
        
        print(f"âœ… æŠ¥å‘Šæ–‡æ¡£: {report_file}")
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        print("\n" + "ğŸš€" * 35)
        print("å¯åŠ¨æ’­å®¢æ–°é—»é‡‡é›†ç³»ç»Ÿ")
        print("ğŸš€" * 35 + "\n")
        
        # 1. é‡‡é›†
        articles = self.collect_demo_data()
        
        # 2. å»é‡
        unique_articles = self.deduplicate(articles)
        
        # 3. åˆ†ç±»å’Œæ‰“åˆ†
        scored_articles = self.categorize_and_score(unique_articles)
        
        # 4. ç”Ÿæˆè„šæœ¬
        script = self.generate_summary(scored_articles)
        
        # 5. ä¿å­˜ç»“æœ
        self.save_results(scored_articles, script)
        
        print("\n" + "=" * 70)
        print("âœ… å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸ!")
        print("=" * 70)
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("1. æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶äº†è§£æ–°é—»å†…å®¹")
        print("2. æ ¹æ®è„šæœ¬JSONç”Ÿæˆæ’­å®¢éŸ³é¢‘")
        print("3. äººå·¥å®¡æ ¸å¹¶è°ƒæ•´å†…å®¹")
        print("4. ä½¿ç”¨TTSå·¥å…·ç”Ÿæˆæœ€ç»ˆéŸ³é¢‘")
        print("\nğŸ’¡ æç¤º:")
        print("- å®é™…éƒ¨ç½²æ—¶ï¼Œæ›¿æ¢æ¼”ç¤ºæ•°æ®ä¸ºçœŸå®APIè°ƒç”¨")
        print("- é…ç½®NewsCatcherå’ŒGDELT APIå¯†é’¥")
        print("- éƒ¨ç½²RSSHubæœåŠ¡ï¼ˆdocker-compose up -dï¼‰")


def main():
    aggregator = NewsAggregator()
    aggregator.run_full_pipeline()


if __name__ == "__main__":
    main()
