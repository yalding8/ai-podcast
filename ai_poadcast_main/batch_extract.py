#!/usr/bin/env python3
"""
æ‰¹é‡æç‚¼æ–°é—»è¦ç‚¹
å…ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ–°é—»ï¼Œç”Ÿæˆä¸­æ–‡æ‘˜è¦ï¼Œç„¶åå†äººå·¥å®¡æ ¸
"""

import argparse
import json
from process_queue import fetch_article_text, extract_key_points

def batch_extract(queue_file="ai_poadcast_main/news_queue.json", min_priority=8,
                  provider=None, model=None):
    """æ‰¹é‡æç‚¼"""
    with open(queue_file) as f:
        queue = json.load(f)
    
    items = [item for item in queue['items'] if item['priority'] >= min_priority]
    
    print(f"ğŸ“¥ å‡†å¤‡æç‚¼ {len(items)} æ¡æ–°é—»...")
    
    results = []
    
    for i, item in enumerate(items, 1):
        print(f"\n[{i}/{len(items)}] {item['title'][:50]}...")
        
        # æŠ“å–æ­£æ–‡
        text = fetch_article_text(item['url'])
        
        if text:
            # æç‚¼è¦ç‚¹
            summary = extract_key_points(item['title'], item['url'], text,
                                         provider=provider, model=model)
            
            results.append({
                **item,
                'chinese_summary': summary,
                'article_length': len(text)
            })
        else:
            results.append({
                **item,
                'chinese_summary': 'âš ï¸ æ— æ³•æŠ“å–æ­£æ–‡',
                'article_length': 0
            })
    
    # ä¿å­˜ç»“æœ
    output_file = "ai_poadcast_main/news_queue_with_summaries.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total': len(results),
            'items': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å·²ä¿å­˜åˆ°: {output_file}")
    
    # ç”Ÿæˆå¯è¯»æŠ¥å‘Š
    report_file = "ai_poadcast_main/daily_review_cn.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# æ¯æ—¥æ–°é—»å®¡æ ¸ï¼ˆä¸­æ–‡æ‘˜è¦ï¼‰\n\n")
        
        for i, item in enumerate(results, 1):
            f.write(f"## [{i}] {item['title']}\n\n")
            f.write(f"**æ¥æºï¼š** {item['source']} | **ä¼˜å…ˆçº§ï¼š** {item['priority']}\n\n")
            f.write(f"**URLï¼š** {item['url']}\n\n")
            f.write(f"### ä¸­æ–‡æç‚¼\n\n")
            f.write(f"{item['chinese_summary']}\n\n")
            f.write("---\n\n")
    
    print(f"âœ… å¯è¯»æŠ¥å‘Š: {report_file}")
    print(f"\nğŸ’¡ ç°åœ¨å¯ä»¥æ‰“å¼€Markdownæ–‡ä»¶æ…¢æ…¢çœ‹ï¼Œå†³å®šå“ªäº›å€¼å¾—å¯¼å…¥")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ‰¹é‡æç‚¼æ–°é—»è¦ç‚¹")
    parser.add_argument("--queue-file", default="ai_poadcast_main/news_queue.json",
                        help="å¾…å¤„ç†æ–°é—»é˜Ÿåˆ—æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--min-priority", type=int, default=8,
                        help="æœ€ä½ä¼˜å…ˆçº§")
    parser.add_argument("--provider", help="è¦ç‚¹ç”Ÿæˆæ¨¡å‹æä¾›æ–¹ï¼ˆå¦‚ openaiã€anthropicï¼‰")
    parser.add_argument("--model", help="è¦ç‚¹ç”Ÿæˆæ¨¡å‹åç§°")
    args = parser.parse_args()
    batch_extract(args.queue_file, args.min_priority, args.provider, args.model)
