#!/usr/bin/env python3
"""
ä½¿ç”¨NewsAPIé‡‡é›†é«˜è´¨é‡å›½é™…æ•™è‚²æ–°é—»
æ³¨å†Œå…è´¹API: https://newsapi.org (æ¯å¤©100æ¬¡è¯·æ±‚)
"""
import os
import json
import requests
from datetime import datetime, timedelta, timezone

API_KEY = os.getenv("NEWSAPI_KEY", "")
BASE_URL = "https://newsapi.org/v2/everything"

QUALITY_QUERIES = [
    "international students visa",
    "university admission policy",
    "study abroad scholarship",
    "IELTS TOEFL exam",
    "university ranking QS THE",
]

QUALITY_DOMAINS = [
    "thepienews.com",
    "monitor.icef.com",
    "insidehighered.com",
    "timeshighereducation.com",
    "universityworldnews.com",
]

def fetch_quality_news():
    if not API_KEY:
        print("âŒ è¯·è®¾ç½® NEWSAPI_KEY ç¯å¢ƒå˜é‡")
        return []
    
    all_articles = []
    from_date = (datetime.now(timezone.utc) - timedelta(days=30)).strftime("%Y-%m-%d")  # æ‰©å±•åˆ°30å¤©
    
    for query in QUALITY_QUERIES:
        params = {
            "q": query,
            "from": from_date,
            "language": "en",
            "sortBy": "relevancy",
            "pageSize": 10,
            "apiKey": API_KEY
        }
        
        try:
            resp = requests.get(BASE_URL, params=params, timeout=10)
            data = resp.json()
            
            if data.get("status") == "ok":
                articles = data.get("articles", [])
                for article in articles:
                    if any(domain in article.get("url", "") for domain in QUALITY_DOMAINS):
                        all_articles.append({
                            "title": article["title"],
                            "url": article["url"],
                            "source": article["source"]["name"],
                            "published": article["publishedAt"],
                            "summary": article.get("description", "")[:200],
                            "priority": 9,
                            "tags": ["newsapi", query.split()[0]]
                        })
                print(f"âœ… {query}: {len(articles)} æ¡")
        except Exception as e:
            print(f"âš ï¸ {query}: {e}")
    
    # å»é‡å¹¶ä¿å­˜
    unique = {item["url"]: item for item in all_articles}.values()
    
    with open("ai_poadcast_main/newsapi_queue.json", "w") as f:
        json.dump({"items": list(unique), "total": len(unique)}, f, indent=2)
    
    print(f"ğŸ’¾ ä¿å­˜ {len(unique)} æ¡é«˜è´¨é‡æ–°é—»")
    return list(unique)

if __name__ == "__main__":
    fetch_quality_news()
